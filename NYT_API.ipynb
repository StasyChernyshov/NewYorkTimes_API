{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynytimes import NYTAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles have been saved to data/nyt_articles_Oil_and_Gasoline\\nyt_articles_Oil_and_Gasoline_20240701_20240710.csv\n",
      "                   pub_date  \\\n",
      "0  2024-07-07T19:55:06+0000   \n",
      "1  2024-07-07T09:00:16+0000   \n",
      "2  2024-07-06T10:00:05+0000   \n",
      "3  2024-07-02T01:23:39+0000   \n",
      "\n",
      "                                            headline  \\\n",
      "0  Officials Urge Coastal Texans to Evacuate, but...   \n",
      "1  New Plan to Target Russia’s Oil Revenue Brings...   \n",
      "2  Facing New ‘Greenwashing’ Law, an Oil Industry...   \n",
      "3  Judge Orders Biden Administration to Resume Pe...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Despite warnings that Beryl could be a “deadly...   \n",
      "1  Treasury officials want to impose penalties on...   \n",
      "2  Oil sands companies pushing a carbon capture p...   \n",
      "3  President Biden had paused new natural gas exp...   \n",
      "\n",
      "                                             snippet  \\\n",
      "0  Despite warnings that Beryl could be a “deadly...   \n",
      "1  Treasury officials want to impose penalties on...   \n",
      "2  Oil sands companies pushing a carbon capture p...   \n",
      "3  President Biden had paused new natural gas exp...   \n",
      "\n",
      "                                      lead_paragraph  \\\n",
      "0  As Beryl chugged toward the Texas Gulf Coast o...   \n",
      "1  Officials in President Biden’s Treasury Depart...   \n",
      "2  When Parliament passed a law last month bannin...   \n",
      "3  A federal judge on Monday ordered the Biden ad...   \n",
      "\n",
      "                                              byline section_name  \\\n",
      "0  By Edgar Sandoval, Maria Jimenez Moya and Jack...         U.S.   \n",
      "1               By Jim Tankersley and Alan Rappeport         U.S.   \n",
      "2                                      By Ian Austen        World   \n",
      "3                                 By Coral Davenport      Climate   \n",
      "\n",
      "                                             web_url              source  \\\n",
      "0  https://www.nytimes.com/2024/07/07/us/texas-ev...  The New York Times   \n",
      "1  https://www.nytimes.com/2024/07/07/us/politics...  The New York Times   \n",
      "2  https://www.nytimes.com/2024/07/06/world/canad...  The New York Times   \n",
      "3  https://www.nytimes.com/2024/07/01/climate/fed...  The New York Times   \n",
      "\n",
      "                                      multimedia_url  \n",
      "0  https://www.nytimes.com/images/2024/07/07/mult...  \n",
      "1  https://www.nytimes.com/images/2024/06/25/mult...  \n",
      "2  https://www.nytimes.com/images/2024/07/06/mult...  \n",
      "3  https://www.nytimes.com/images/2024/07/01/mult...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Replace with your actual API key\n",
    "api_key = 'xwj9A1dAGBZGFphILjeRNGFpVy79kRll'\n",
    "\n",
    "# Define the query parameters\n",
    "query = \"Oil and Gasoline\"\n",
    "start_date = \"20240701\"  # YYYYMMDD format\n",
    "end_date = \"20240710\"    # YYYYMMDD format\n",
    "sort_order = \"newest\"\n",
    "\n",
    "# Base URL for the API request\n",
    "base_url = f\"https://api.nytimes.com/svc/search/v2/articlesearch.json?q={query}&begin_date={start_date}&end_date={end_date}&sort={sort_order}&api-key={api_key}\"\n",
    "\n",
    "# Initialize list to collect articles\n",
    "article_data = []\n",
    "page = 0\n",
    "max_pages = 5  # Set the maximum number of pages to fetch\n",
    "\n",
    "while page < max_pages:\n",
    "    url = f\"{base_url}&page={page}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data: {response.status_code}\")\n",
    "        break\n",
    "\n",
    "    data = response.json()\n",
    "    articles = data['response']['docs']\n",
    "    if not articles:\n",
    "        break\n",
    "\n",
    "    for article in articles:\n",
    "        pub_date = article.get('pub_date', 'N/A')\n",
    "        headline = article['headline'].get('main', 'N/A')\n",
    "        abstract = article.get('abstract', 'N/A')\n",
    "        snippet = article.get('snippet', 'N/A')\n",
    "        lead_paragraph = article.get('lead_paragraph', 'N/A')\n",
    "        byline = article['byline'].get('original', 'N/A') if article.get('byline') else 'N/A'\n",
    "        section_name = article.get('section_name', 'N/A')\n",
    "        web_url = article.get('web_url', 'N/A')\n",
    "        source = article.get('source', 'N/A')\n",
    "\n",
    "        # Extract multimedia URL\n",
    "        multimedia_url = 'N/A'\n",
    "        if article.get('multimedia'):\n",
    "            for media in article['multimedia']:\n",
    "                if media['subtype'] == 'xlarge':\n",
    "                    multimedia_url = f\"https://www.nytimes.com/{media['url']}\"\n",
    "                    break\n",
    "\n",
    "        article_data.append([pub_date, headline, abstract, snippet, lead_paragraph, byline, section_name, web_url, source, multimedia_url])\n",
    "\n",
    "    page += 1\n",
    "\n",
    "df = pd.DataFrame(article_data, columns=['pub_date', 'headline', 'abstract', 'snippet', 'lead_paragraph', 'byline', 'section_name', 'web_url', 'source', 'multimedia_url'])\n",
    "\n",
    "# Define the path where you want to save the file\n",
    "output_dir = \"data/nyt_articles_Oil_and_Gasoline\"  # Simplified directory name\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "output_file = os.path.join(output_dir, f\"nyt_articles_Oil_and_Gasoline_{start_date}_{end_date}.csv\")  # Simplified file name\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Articles have been saved to {output_file}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
